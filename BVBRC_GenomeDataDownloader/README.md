# BVBRC_GenomeDataDownloader

## 簡介

這是我第一次寫 Pyhton script，主要是為了從 BV-BRC 下載「大量」基因體註解檔案。並且為了之後的 pan-genome 分析，必須把這些檔案處理成 Roary 能夠接受的 `.gff` 格式檔案。因此，這個腳本著重於批量處理檔案的下載、讀寫、移動；對於這一點，我是基於 Ubuntu 的 Bash shell 來撰寫的，腳本中透過 os 或 subprocess 套件呼叫的一些外部指令也都是基於 Bash，如果要在 Windows 執行的話需要修改一下。這個腳本是我在 jupyter notebook 上編輯的，所以在腳本中會發現許多 `# %%` (用來標示 `.ipynb` 中的 cells )，那是把檔案轉成 `.py` 時遺留下來的記號。我沒有加上 shebang，主要是曾經發生過 shebang 和設想的位置不同，結果不能執行的問題；而且搞不好會有人想在特殊的環境下執行 (我自己就是在 conda 的環境中測試的)；所以，如果有幸在下的腳本能幫助到各位，動動手指在前面加上 "python" 吧。腳本中的註解還算完整，因為當我完成它，真的非常高興！想要把它分享出來。註解一方面能防止我忘記代碼的意義，也方便其他人理解。雖然這個腳本還有很多缺點，光是我自己就能提出幾個，也沒有針對效率做最優化 (嘆專業知識不足QQ)，不過至少目前為止它還算堪用。其實如果要達成同樣的結果，或許可以用分離的一些 Bash 指令達成。不過一方面是因為好奇，另一方面是因為對 Bash 實在有點陌生，所以儘管老師建議我藉機試試，最後我還是用 Python 實現了> <

## 功能

這個 Python 腳本的主要功能如下：

1. 提示使用者輸入 CSV 檔案的絕對路徑，該檔案包含了病症名稱和相關的基因組 ID。
2. 讀取 CSV 檔案的第一行，獲取病症的名稱。
3. 為每一種病症創建一個資料夾，並將當前工作目錄切換到該資料夾。
4. 讀取 CSV 檔案的每一行，將每一種病症對應的基因組 ID 寫入到一個新的文本檔案中。
5. 為每一種要下載的檔案格式（如 ".PATRIC.gff" 和 ".fna"）創建一個新的資料夾。
6. 使用 `wget` 命令從 FTP 網址下載每一種病症的每一個基因組 ID 對應的檔案。
7. 如果下載過程中出現錯誤，則將出錯的基因組 ID 寫入到一個新的文本檔案中。
8. 確認並取得成功下載 .gff 和 .fna 檔案的基因組 ID。
9. 對於每一個成功下載的基因組 ID，將其對應的 .fna 和 .gff 檔案合併，並將合併後的檔案移動到上一層資料夾中。
10. 刪除 .fna 和 .PATRIC.gff 資料夾（這部分的程式碼被註解掉了）。
11. 切換到上一層目錄，準備處理下一種病症。

請注意，這個腳本需要在能夠執行 `wget` 命令的環境中運行，並且需要有讀取和寫入檔案的權限。

## 測試

首先，要準備一個 CSV 檔案存放 BV-BRC 所定義的 genome ID (或 PATRIC ID)，檔案格式大致如下：

```
asymptomatic,bacteremia,UTI,sepsis
573.31029,573.14940,1263871.10,573.12478
573.31030,573.14941,573.12456,573.12681
573.31031,573.14942,573.12482,573.12682
573.31034,573.14944,573.12487,573.12683
573.31035,573.14945,573.12759,573.12684
573.31038,573.14946,573.12760,573.12685
573.32131,573.14947,573.12761,573.12686
573.32132,573.14948,573.12762,573.12687
573.32133,573.14949,573.12763,573.12688
573.32134,573.14950,333333333,573.12689
         ,222222222,573.12764,
111111111,444444444,555555555,
```
建議將我的腳本和這個 CSV 檔放在同一個目錄底下執行。

上方的 CSV 格式範例也可以用來測試腳本能否正常運行，其中的 1111* ~ 5555* 是偽 ID，用來測試無法下載檔案時腳本的狀況。

我的腳本用到了幾個預設模組，一般來說應該是不用重新安裝，不過還是提醒一下：`csv`, `os`, `re`, `subprocess`

---

# English introduction generated by GPT

## Project Overview

This Python script is designed to download and process genomic data from a CSV file. The script will prompt the user for the absolute path of the CSV file, which should contain the names of diseases in the first row. The script will then download the corresponding genomic data from a specified FTP server, organize the data into directories for each disease, and perform various processing tasks on the data.

## Dependencies

This script requires the following Python modules:

- `csv`
- `os`
- `re`
- `subprocess`

## How to Run

1. Run the script in your Python environment.
2. When prompted, enter the absolute path of your CSV file.

## Detailed Explanation

The script performs the following steps:

1. **CSV File Input**: The script prompts the user for the absolute path of a CSV file. The first row of the CSV file should contain the names of diseases.

2. **Data Download**: The script downloads genomic data from a specified FTP server. The data is organized into directories for each disease.

3. **Data Processing**: The script performs various processing tasks on the downloaded data. These tasks include:
   - Creating a text file with genome IDs for each disease.
   - Downloading files in specified formats (".PATRIC.gff", ".fna") for each genome ID.
   - Merging .fna and .gff files for genome IDs that have both file types available.

4. **Error Handling**: If a file fails to download, the script records the genome ID in an "error-ids.txt" file.

5. **Directory Navigation**: The script navigates through directories using the `os.chdir()` function to organize and process the data.

## Note

The script includes commented-out code that can be used to delete the .fna and .PATRIC.gff directories after the .fna and .gff files have been merged. To use this functionality, remove the comments from the relevant lines of code.

## Disclaimer

This script is intended for educational purposes and should be used with caution when downloading and processing large amounts of data. Always ensure you have permission to download and use the data, and that you have sufficient storage space on your computer.
